#
# Utility functions to scrap data from the air quality stations in Jaén
#
# April 2019 - Francisco Charte
#

library(lubridate)
library(dplyr)
library(httr)
library(rvest)
library(stringr)

# Components of the URL to request from the server
#
baseURL <- "http://www.juntadeandalucia.es/medioambiente/atmosfera/informes_siva/"
months <- c("ene","feb","mar","abr","may","jun","jul","ago","sep","oct","nov","dic")
place <- "/nja"  # This component sets the province to "Jaén". It should be changed to get data from other places
extension <- ".htm"


#' Composes the URL to get air quality data for a given day
#'
#' @param aday The `Date` to retrieve
#'
#' @return A string with the URL
#' @export
#'
#' @examples
#' makeURL(as.Date("2019-03-31"))
#' 
makeURL <- function(aday) {
  stopifnot(lubridate::is.Date(aday))
  
  paste0(baseURL,
         months[lubridate::month(aday)],
         lubridate::year(aday)-2000,
         place,
         format(aday, "%y%m%d"),
         extension)
}

#' Search the stations' tables for a specific location inside a province
#'
#' @param tables The XML nodes containing the tables retrieved from the web site
#' @param aPlace Name of the location we are interested in
#'
#' @return A `data.frame` containing the ID of each table and the name of the statation
#' @export
#'
#' @examples
searchTable <- function(tables, aPlace) {
  idxs <- c()
  stations <- c()
  
  for (idx in seq_len(length(tables))) {
    table <- rvest::html_table(tables[idx], fill = TRUE)[[1]]
    if (!is.na(table[2, 1]) && !is.na(table[2, 2]) &&
        table[2, 1] == "Municipio" && table[2, 2] == aPlace) {
      idxs <- c(idxs, idx + 1)
      stations <- c(stations, table[3,2])
    }
  }
  data.frame(tableID = idxs, station = stations)
}

#' Retrieves the given URL an extract from the page the data tables
#'
#' @param aURL The URL of the page to retrieve, generated by the `makeURL()` function
#'
#' @return A list of `data.frame` with the data tables
#' @export
#'
#' @examples
getTables <- function(aURL, aPlace) {
  tables <- httr::GET(aURL) %>%
    httr::content(as = "parsed", encoding = "iso8859-1") %>%
    rvest::xml_nodes("table")
  
  idxs <- searchTable(tables, aPlace)
  
  lapply(seq_len(nrow(idxs)), function(idx) {
    data <- rvest::html_table(tables[[idxs$tableID[idx]]],
                              header = TRUE, fill = TRUE)
    data$Station <- idxs$station[idx]
    data <- data[-nrow(data),]
    data
  })
}

#' Removes the columns containing NAs, generated when some stations do not have all the variables
#'
#' @param df The `data.frame` having the data
#'
#' @return The same `data.frame` after the NA columns have been removed
#' @export
#'
#' @examples
removeNAcol <- function(df) {
  df[sapply(df, function(x) !all(is.na(x)))]
}

#' Gets the air quality data for a given day, cleaning the data tables and joining them into a single `data.frame`
#'
#' @param aURL The URL corresponding to the day of interest
#' @param aPlace Location of interest inside the province
#' @param verbose If `TRUE` the function shows a dot in the terminal
#'
#' @return A `data.frame` with the retrieved data
#' @export
#'
#' @examples
getDayData <- function(aURL, aPlace = "JAEN", verbose = TRUE) {
  if(verbose) cat(".")
  
  results <- getTables(aURL, aPlace)
  
  if(length(results) != 2) return (NULL)
  
  stationA <- removeNAcol(results[[1]])
  stationB <- removeNAcol(results[[2]])
  
  if (nrow(stationA) == 0) {
    return (stationB)
  }
  
  if (nrow(stationB) == 0) {
    return (stationA)
  }
  
  if(length(setdiff(names(stationB), names(stationA))) > 0) {
    stationA[setdiff(names(stationB), names(stationA))] <- NA
  }
  
  if(length(setdiff(names(stationA), names(stationB))) > 0) {
    stationB[setdiff(names(stationA), names(stationB))] <- NA
  }
  stationB <- stationB[ , names(stationA)]
  day <- bind_rows(stationA, stationB)
  
  day
}

#' Gets the data for a range of dates, by calling the `getDayData()` with the proper URLs
#'
#' @param fromDate Starting date
#' @param toDate  Ending date
#'
#' @return A `data.frame` with all the data for the date range
#' @export
#'
#' @examples
getDaysData <- function(fromDate, toDate) {
  dates <- seq.Date(
    from = as.Date(fromDate),
    to   = as.Date(toDate),
    by = "day")
  
  urls <- makeURL(dates)
  
  data <- bind_rows(lapply(urls, getDayData))
  data[order(data$`FECHA-HORA`),]
}

#' Gets the data for a full year
#'
#' @param aYear The year of interest
#' @param aPlace The place
#'
#' @return A `data.frame` with all the data
#' @export
#'
#' @examples
getYearData <- function(aYear) {
  getDaysData(fromDate = as.Date(paste0(aYear, "-01-01")),
              toDate =  as.Date(paste0(aYear, "-12-31")))
}
